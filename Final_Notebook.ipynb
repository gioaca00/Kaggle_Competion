{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle as pkl\n",
    "from skopt import BayesSearchCV"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_cwd= os.getcwd()\n",
    "path_data=path_cwd+'/Data/'\n",
    "\n",
    "#train = pd.read_csv(path_data+ \"train.csv\")\n",
    "#train.to_parquet(path_data+ \"train.parquet\", engine=\"fastparquet\")\n",
    "#train = pd.read_parquet(path_data+ \"train.parquet\", engine=\"fastparquet\")\n",
    "sample = pd.read_csv(path_data+'sample_submission.csv')\n",
    "labels = pd.read_csv(path_data+'train_labels.csv')\n",
    "labels['session'] = labels.session_id.apply(lambda x: int(x.split('_')[0]) )\n",
    "labels['q'] = labels.session_id.apply(lambda x: int(x.split('_')[-1][1:]) )\n",
    "\n",
    "test = pd.read_csv(path_data+'test.csv')\n",
    "#times = pd.read_parquet(\"df_times.parquet\", engine=\"fastparquet\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df):\n",
    "    # drop useless columns\n",
    "    df.drop(['fullscreen','hq','music','level','room_coor_x','room_coor_y','screen_coor_x','screen_coor_y',\n",
    "                    'hover_duration',], axis=1, inplace=True)\n",
    "    # extract times\n",
    "    times = df.elapsed_time.diff().fillna(0)\n",
    "    times[times < 0] = 0\n",
    "    df['times'] = times\n",
    "    df.drop(['elapsed_time'], axis=1, inplace=True)\n",
    "    # create room_changed column\n",
    "    change = df['room_fqid'].ne(df['room_fqid'].shift().bfill()).astype(int)\n",
    "    change[df['index'] == 0] = 1 # manually correct where session starts\n",
    "    df['room_changed'] = change.cumsum()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet(path_data + \"train.parquet\", engine=\"fastparquet\")\n",
    "train = preprocessing(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>index</th>\n",
       "      <th>event_name</th>\n",
       "      <th>name</th>\n",
       "      <th>page</th>\n",
       "      <th>text</th>\n",
       "      <th>fqid</th>\n",
       "      <th>room_fqid</th>\n",
       "      <th>text_fqid</th>\n",
       "      <th>level_group</th>\n",
       "      <th>times</th>\n",
       "      <th>room_changed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>0</td>\n",
       "      <td>cutscene_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>undefined</td>\n",
       "      <td>intro</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.intro</td>\n",
       "      <td>0-4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>1</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Whatcha doing over there, Jo?</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>0-4</td>\n",
       "      <td>1323.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>2</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just talking to Teddy.</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>0-4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>3</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I gotta run to my meeting!</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>0-4</td>\n",
       "      <td>316.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>4</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Can I come, Gramps?</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>0-4</td>\n",
       "      <td>716.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          session_id  index      event_name   name  page  \\\n",
       "0  20090312431273200      0  cutscene_click  basic   NaN   \n",
       "1  20090312431273200      1    person_click  basic   NaN   \n",
       "2  20090312431273200      2    person_click  basic   NaN   \n",
       "3  20090312431273200      3    person_click  basic   NaN   \n",
       "4  20090312431273200      4    person_click  basic   NaN   \n",
       "\n",
       "                            text    fqid                       room_fqid  \\\n",
       "0                      undefined   intro  tunic.historicalsociety.closet   \n",
       "1  Whatcha doing over there, Jo?  gramps  tunic.historicalsociety.closet   \n",
       "2         Just talking to Teddy.  gramps  tunic.historicalsociety.closet   \n",
       "3     I gotta run to my meeting!  gramps  tunic.historicalsociety.closet   \n",
       "4            Can I come, Gramps?  gramps  tunic.historicalsociety.closet   \n",
       "\n",
       "                                           text_fqid level_group   times  \\\n",
       "0               tunic.historicalsociety.closet.intro         0-4     0.0   \n",
       "1  tunic.historicalsociety.closet.gramps.intro_0_...         0-4  1323.0   \n",
       "2  tunic.historicalsociety.closet.gramps.intro_0_...         0-4     0.0   \n",
       "3  tunic.historicalsociety.closet.gramps.intro_0_...         0-4   316.0   \n",
       "4  tunic.historicalsociety.closet.gramps.intro_0_...         0-4   716.0   \n",
       "\n",
       "   room_changed  \n",
       "0             1  \n",
       "1             1  \n",
       "2             1  \n",
       "3             1  \n",
       "4             1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 1\n",
       "1                 1\n",
       "2                 1\n",
       "3                 1\n",
       "4                 1\n",
       "             ...   \n",
       "26296941    1704610\n",
       "26296942    1704610\n",
       "26296943    1704610\n",
       "26296944    1704610\n",
       "26296945    1704610\n",
       "Name: room_changed, Length: 26296946, dtype: int32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['room_changed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "times1 = train[train['level_group']=='0-4'].drop(['level_group'],axis = 1).reset_index(drop=True)\n",
    "times2 = train[train['level_group']=='5-12'].drop(['level_group'],axis = 1).reset_index(drop=True)\n",
    "times3 = train[train['level_group']=='13-22'].drop(['level_group'],axis = 1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to parquet times\n",
    "times1.to_parquet(path_data+ \"times1.parquet\", engine=\"fastparquet\")\n",
    "times2.to_parquet(path_data+ \"times2.parquet\", engine=\"fastparquet\")\n",
    "times3.to_parquet(path_data+ \"times3.parquet\", engine=\"fastparquet\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recover data without running preprocessing\n",
    "times1 = pd.read_parquet(path_data+ \"times1.parquet\", engine=\"fastparquet\")\n",
    "times2 = pd.read_parquet(path_data+ \"times2.parquet\", engine=\"fastparquet\")\n",
    "times3 = pd.read_parquet(path_data+ \"times3.parquet\", engine=\"fastparquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def notification_text(level):\n",
    "    if level == '0-4':\n",
    "        useful = ['Gramps is in trouble for losing papers?','This looks like a clue!',\n",
    "                \"I'll record this in my notebook.\",\"The slip is from 1916 but the team didn't start until 1974!\"]\n",
    "        useless = ['Found it!',\"This can't be right!\",'Gramps is a great historian!',\n",
    "                \"That's it!\",'Hooray, a boring old shirt.','A boring old shirt.','Gramps is the best historian ever!']\n",
    "    elif level == '5-12':\n",
    "        useful = ['This place was around in 1916! I can start there!','Youmans was a suffragist!',\n",
    "                  \"And look! She's wearing the shirt!\"]\n",
    "        useless = [\"It's a match!\",'Theodora Youmans must be the owner!','She helped get votes for women!',\n",
    "                   'Wells! What was he doing here? I should ask the librarian.','Hey, this is Youmans!','I should go to the Capitol and tell everyone!']\n",
    "    elif level == '13-22':\n",
    "        useful = [\"That hoofprint doesn't match the flag!\",'\\\\Ecology flag, by Ron Cobb.\\\\',\"Hey! That's Governor Nelson in front of our flag!\",\n",
    "                  \"And look! She's wearing the shirt!\",'Ooh... \\\\Ecology flag, by Ron Cobb.\\\\']\n",
    "        useless = ['Those are the same glasses!', \"The archivist must've taken Teddy!\",'Look at all those activists!', 'This is perfect for the exhibit.',\n",
    "       'I should go to the Capitol and tell Mrs. M!','Hey, this is Youmans!','I should go to the Capitol and tell everyone!']\n",
    "    return useful, useless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_identifiers(times,level):\n",
    "    # rooms\n",
    "    rooms = times['room_fqid'].unique()\n",
    "    # page\n",
    "    notebook_t = times[times['page'].isnull() == 0]\n",
    "    pages_id = list(notebook_t['page'].unique())\n",
    "    # objects\n",
    "    object_t = times[times['event_name'] == 'object_click']\n",
    "    objects_id = list(object_t['fqid'].unique())\n",
    "    # people\n",
    "    people_t = times[times['event_name'] == 'person_click']\n",
    "    people_id = people_t.fqid.unique()\n",
    "    # observations\n",
    "    obs_t = times[times['event_name'] == 'observation_click']\n",
    "    obs_id = list(obs_t['fqid'].unique())\n",
    "    # notifications\n",
    "    noti_t = times[times['event_name'] == 'notification_click']\n",
    "    useful = notification_text(level)\n",
    "    noti_useful_t = noti_t[noti_t['text'].isin(useful)]\n",
    "    noti_useful_id = list(noti_useful_t['text'].unique())\n",
    "    # create dictionary\n",
    "    identifiers = {'rooms' : rooms, 'pages_id' : pages_id, 'objects_id' : objects_id, 'persons': people_id, 'obs_id': obs_id, 'noti_useful_id': noti_useful_id}\n",
    "    return identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extractor(grouped,ids, identifiers, stats, stats_names, general_name):\n",
    "    '''\n",
    "    :param grouped: group by dataframe indexed by id and ONE other column whose values must be in identifiers\n",
    "    :param identifiers: list of all possible identifiers\n",
    "    :param stats: functions to use for aggregating\n",
    "    :param stats_names: names for the fucntions precedeed by _\n",
    "    :param general_name: followed by _\n",
    "    :return: a pandas dataframe\n",
    "    '''\n",
    "    d = {general_name + str(identifier) + stat: [] for identifier in identifiers for stat in stats_names}\n",
    "    for id in ids:\n",
    "        if id not in grouped.index.get_level_values('session_id'):\n",
    "            for identifier in identifiers:\n",
    "                for stat, stat_name in zip(stats,stats_names):\n",
    "                    d[general_name + str(identifier) + stat_name] +=[0]\n",
    "        else:\n",
    "            match = grouped.loc[id] # contains list of times for that player\n",
    "            for identifier in identifiers:\n",
    "                for stat, stat_name in zip(stats,stats_names):\n",
    "                    if identifier in match.index:\n",
    "                        d[general_name + str(identifier)+ stat_name] += [stat(match.loc[identifier].times)]\n",
    "                    else:\n",
    "                        d[general_name + str(identifier) + stat_name] +=[0]\n",
    "    return pd.DataFrame(d, index=ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(times1, level):\n",
    "    ids = times1['session_id'].unique()\n",
    "    identifiers = extract_identifiers(times1,level)\n",
    "    # times per room\n",
    "    group_rooms = times1.groupby(by=['session_id','room_fqid','room_changed']).agg({'times':'sum'})\n",
    "    group_rooms = group_rooms.reset_index(level=[0,1]).groupby(by=['session_id', 'room_fqid']).agg({'times': lambda x: list(x)})\n",
    "    rooms_df=feature_extractor(group_rooms,ids,identifiers['rooms'],stats=[np.mean, np.std, len],stats_names=['_mean','_std', '_n'], general_name='rooms_')\n",
    "    # checkpoint\n",
    "    checkpoint_times = times1[times1['event_name'] == 'checkpoint']\n",
    "    group_checkpoint = checkpoint_times.groupby(by=['session_id','event_name']).agg({'times':lambda x: list(x)})\n",
    "    checkpoint_df = feature_extractor(group_checkpoint,ids, identifiers = ['checkpoint'], \n",
    "                                      stats=[np.mean, np.std, len], stats_names=['_mean','_std', '_n'], general_name='checkpoint_')\n",
    "    # page\n",
    "    notebook_times = times1[times1['page'].isnull() == 0]\n",
    "    notebook_times = notebook_times[notebook_times['name']!='open']\n",
    "    group_pages = notebook_times.groupby(by=['session_id','page']).agg({'times':lambda x: list(x)})\n",
    "    pages_df = feature_extractor(group_pages,ids, identifiers = identifiers['pages_id'], stats=[np.mean, np.std, len], stats_names=['_mean','_std', '_n'], general_name='page_')\n",
    "    # objects\n",
    "    object_times = times1[(times1['event_name'] == 'object_click') | (times1['event_name'] == 'object_click')]\n",
    "    group_objects = object_times.groupby(by=['session_id','fqid']).agg({'times':lambda x: list(x)})\n",
    "    objects_df = feature_extractor( group_objects,ids, identifiers = identifiers['objects_id'], stats=[np.mean, np.std, len], stats_names=['_mean','_std', '_n'], general_name='object_')\n",
    "    # cut-scene\n",
    "    row_filter = times1.event_name=='cutscene_click'\n",
    "    column_filter= ['session_id', 'room_fqid','times']\n",
    "    cut_scene_clicks=times1.loc[row_filter,column_filter]\n",
    "    grouped=cut_scene_clicks.groupby(by=['session_id', 'room_fqid']).agg({'times': lambda x: list(x)})\n",
    "    cut_scene_clicks_df=feature_extractor(grouped,ids,identifiers['rooms'],stats=[np.mean, np.std],stats_names=['_mean','_std'], general_name='cutscene_')\n",
    "    # people\n",
    "    row_filter = times1.event_name=='person_click'\n",
    "    column_filter= ['session_id', 'fqid','times']\n",
    "    person_clicks=times1.loc[row_filter,column_filter]\n",
    "    grouped = person_clicks.groupby(by=['session_id', 'fqid']).agg({'times': lambda x: list(x)})\n",
    "    person_clicks_df=feature_extractor(grouped,ids,identifiers['persons'],stats=[np.mean, np.std,len],stats_names=['_mean','_std','_n'], general_name='persons_')\n",
    "    # observation\n",
    "    obs_times = times1[times1['event_name'] == 'observation_click']\n",
    "    group_obs = obs_times.groupby(by=['session_id','fqid']).agg({'times':lambda x: list(x)})\n",
    "    obs_df = feature_extractor(group_obs,ids, identifiers = identifiers['obs_id'], stats=[np.mean, np.std, len], stats_names=['_mean','_std', '_n'], general_name='obs_')\n",
    "    # notification\n",
    "    useful = notification_text(level)\n",
    "    noti_times = times1[times1['event_name'] == 'notification_click']\n",
    "    noti_useful = noti_times[noti_times['text'].isin(useful)]\n",
    "    group_noti_useful = noti_useful.groupby(by=['session_id','text']).agg({'times':lambda x: list(x)})\n",
    "    noti_useful_df = feature_extractor(group_noti_useful,ids, identifiers = identifiers['noti_useful_id'], stats=[np.mean, np.std, len], stats_names=['_mean','_std', '_n'], general_name='notification_')\n",
    "    # aggregate features\n",
    "    features = pd.concat([rooms_df, checkpoint_df, pages_df, objects_df, cut_scene_clicks_df, person_clicks_df, obs_df, noti_useful_df],axis=1)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "features1 = features(times1,'0-4')\n",
    "features1.to_csv(path_data + 'features1_new.csv')\n",
    "features2 = features(times2,'5-12')\n",
    "features2.to_csv(path_data + 'features2_new.csv')\n",
    "features3 = features(times3,'13-22')\n",
    "features3.to_csv(path_data + 'features3_new.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features selection with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features1 = pd.read_csv(path_data + 'features1_new.csv', index_col=0)\n",
    "features2 = pd.read_csv(path_data + 'features2_new.csv', index_col=0)\n",
    "features3 = pd.read_csv(path_data + 'features3_new.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features1 = features1.loc[:, (features1 != features1.iloc[0]).any()] \n",
    "features2 = features2.loc[:, (features2 != features2.iloc[0]).any()]\n",
    "features3 = features3.loc[:, (features3 != features3.iloc[0]).any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rooms_tunic.historicalsociety.closet_mean</th>\n",
       "      <th>rooms_tunic.historicalsociety.closet_std</th>\n",
       "      <th>rooms_tunic.historicalsociety.closet_n</th>\n",
       "      <th>rooms_tunic.historicalsociety.basement_mean</th>\n",
       "      <th>rooms_tunic.historicalsociety.basement_std</th>\n",
       "      <th>rooms_tunic.historicalsociety.basement_n</th>\n",
       "      <th>rooms_tunic.historicalsociety.entry_mean</th>\n",
       "      <th>rooms_tunic.historicalsociety.entry_std</th>\n",
       "      <th>rooms_tunic.historicalsociety.entry_n</th>\n",
       "      <th>rooms_tunic.historicalsociety.collection_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>obs_doorblock_n</th>\n",
       "      <th>obs_block_tomap2_mean</th>\n",
       "      <th>obs_block_tomap2_std</th>\n",
       "      <th>obs_block_tomap2_n</th>\n",
       "      <th>obs_block_tomap1_mean</th>\n",
       "      <th>obs_block_tomap1_std</th>\n",
       "      <th>obs_block_tomap1_n</th>\n",
       "      <th>obs_block_0_mean</th>\n",
       "      <th>obs_block_0_std</th>\n",
       "      <th>obs_block_0_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20090312431273200</th>\n",
       "      <td>24519.5</td>\n",
       "      <td>13504.5</td>\n",
       "      <td>2</td>\n",
       "      <td>4153.0</td>\n",
       "      <td>1531.050837</td>\n",
       "      <td>3</td>\n",
       "      <td>10835.75</td>\n",
       "      <td>12478.724201</td>\n",
       "      <td>4</td>\n",
       "      <td>26613.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20090312433251036</th>\n",
       "      <td>20429.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4814.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>23916.00</td>\n",
       "      <td>13814.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>89960.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20090312455206810</th>\n",
       "      <td>9887.5</td>\n",
       "      <td>8286.5</td>\n",
       "      <td>2</td>\n",
       "      <td>105393.5</td>\n",
       "      <td>104027.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>17012.00</td>\n",
       "      <td>8105.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>32396.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20090313091715820</th>\n",
       "      <td>23842.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>14187.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>16209.00</td>\n",
       "      <td>5947.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>26409.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20090313571836404</th>\n",
       "      <td>37649.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3833.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>27308.50</td>\n",
       "      <td>6925.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>40223.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   rooms_tunic.historicalsociety.closet_mean  \\\n",
       "20090312431273200                                    24519.5   \n",
       "20090312433251036                                    20429.0   \n",
       "20090312455206810                                     9887.5   \n",
       "20090313091715820                                    23842.0   \n",
       "20090313571836404                                    37649.0   \n",
       "\n",
       "                   rooms_tunic.historicalsociety.closet_std  \\\n",
       "20090312431273200                                   13504.5   \n",
       "20090312433251036                                       0.0   \n",
       "20090312455206810                                    8286.5   \n",
       "20090313091715820                                       0.0   \n",
       "20090313571836404                                       0.0   \n",
       "\n",
       "                   rooms_tunic.historicalsociety.closet_n  \\\n",
       "20090312431273200                                       2   \n",
       "20090312433251036                                       1   \n",
       "20090312455206810                                       2   \n",
       "20090313091715820                                       1   \n",
       "20090313571836404                                       1   \n",
       "\n",
       "                   rooms_tunic.historicalsociety.basement_mean  \\\n",
       "20090312431273200                                       4153.0   \n",
       "20090312433251036                                       4814.0   \n",
       "20090312455206810                                     105393.5   \n",
       "20090313091715820                                      14187.0   \n",
       "20090313571836404                                       3833.0   \n",
       "\n",
       "                   rooms_tunic.historicalsociety.basement_std  \\\n",
       "20090312431273200                                 1531.050837   \n",
       "20090312433251036                                    0.000000   \n",
       "20090312455206810                               104027.500000   \n",
       "20090313091715820                                    0.000000   \n",
       "20090313571836404                                    0.000000   \n",
       "\n",
       "                   rooms_tunic.historicalsociety.basement_n  \\\n",
       "20090312431273200                                         3   \n",
       "20090312433251036                                         1   \n",
       "20090312455206810                                         2   \n",
       "20090313091715820                                         1   \n",
       "20090313571836404                                         1   \n",
       "\n",
       "                   rooms_tunic.historicalsociety.entry_mean  \\\n",
       "20090312431273200                                  10835.75   \n",
       "20090312433251036                                  23916.00   \n",
       "20090312455206810                                  17012.00   \n",
       "20090313091715820                                  16209.00   \n",
       "20090313571836404                                  27308.50   \n",
       "\n",
       "                   rooms_tunic.historicalsociety.entry_std  \\\n",
       "20090312431273200                             12478.724201   \n",
       "20090312433251036                             13814.000000   \n",
       "20090312455206810                              8105.000000   \n",
       "20090313091715820                              5947.000000   \n",
       "20090313571836404                              6925.500000   \n",
       "\n",
       "                   rooms_tunic.historicalsociety.entry_n  \\\n",
       "20090312431273200                                      4   \n",
       "20090312433251036                                      2   \n",
       "20090312455206810                                      2   \n",
       "20090313091715820                                      2   \n",
       "20090313571836404                                      2   \n",
       "\n",
       "                   rooms_tunic.historicalsociety.collection_mean  ...  \\\n",
       "20090312431273200                                        26613.0  ...   \n",
       "20090312433251036                                        89960.0  ...   \n",
       "20090312455206810                                        32396.0  ...   \n",
       "20090313091715820                                        26409.0  ...   \n",
       "20090313571836404                                        40223.0  ...   \n",
       "\n",
       "                   obs_doorblock_n  obs_block_tomap2_mean  \\\n",
       "20090312431273200                0                    0.0   \n",
       "20090312433251036                0                    0.0   \n",
       "20090312455206810                0                    0.0   \n",
       "20090313091715820                0                    0.0   \n",
       "20090313571836404                0                    0.0   \n",
       "\n",
       "                   obs_block_tomap2_std  obs_block_tomap2_n  \\\n",
       "20090312431273200                   0.0                   0   \n",
       "20090312433251036                   0.0                   0   \n",
       "20090312455206810                   0.0                   0   \n",
       "20090313091715820                   0.0                   0   \n",
       "20090313571836404                   0.0                   0   \n",
       "\n",
       "                   obs_block_tomap1_mean  obs_block_tomap1_std  \\\n",
       "20090312431273200                    0.0                   0.0   \n",
       "20090312433251036                    0.0                   0.0   \n",
       "20090312455206810                    0.0                   0.0   \n",
       "20090313091715820                    0.0                   0.0   \n",
       "20090313571836404                    0.0                   0.0   \n",
       "\n",
       "                   obs_block_tomap1_n  obs_block_0_mean  obs_block_0_std  \\\n",
       "20090312431273200                   0               0.0              0.0   \n",
       "20090312433251036                   0               0.0              0.0   \n",
       "20090312455206810                   0               0.0              0.0   \n",
       "20090313091715820                   0               0.0              0.0   \n",
       "20090313571836404                   0               0.0              0.0   \n",
       "\n",
       "                   obs_block_0_n  \n",
       "20090312431273200              0  \n",
       "20090312433251036              0  \n",
       "20090312455206810              0  \n",
       "20090313091715820              0  \n",
       "20090313571836404              0  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score original:  0.5827721728611109\n",
      "Score light:  0.5426943482574975\n",
      "Score original:  0.661041759185482\n",
      "Score light:  0.6274734588242333\n",
      "Score original:  0.6487155442282666\n",
      "Score light:  0.613756739675164\n"
     ]
    }
   ],
   "source": [
    "lst_valid = []\n",
    "lst_pred = []\n",
    "lst_pred_selected = []\n",
    "conf_matrix = {}\n",
    "conf_matrix_selected = {}\n",
    "original_f1score = []\n",
    "light_f1score = []\n",
    "features_to_keep = {}\n",
    "flag1 = 0\n",
    "flag2 = 0\n",
    "for q_no in range(1,19):\n",
    "    if q_no <= 3:\n",
    "        features = features1\n",
    "    elif q_no <= 13:\n",
    "        features = features2\n",
    "        if flag1 == 0:\n",
    "            print('Score original: ',f1_score(lst_valid, lst_pred,average='macro'))\n",
    "            print('Score light: ',f1_score(lst_valid, lst_pred_selected,average='macro'))\n",
    "            flag1 = 1\n",
    "    else:\n",
    "        if flag2 == 0:\n",
    "            print('Score original: ',f1_score(lst_valid, lst_pred,average='macro'))\n",
    "            print('Score light: ',f1_score(lst_valid, lst_pred_selected,average='macro'))\n",
    "            flag2 = 1\n",
    "        features = features3\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels.loc[labels.q==q_no].set_index('session')['correct'], test_size=0.2, random_state=42,\n",
    "                                                    stratify=labels.loc[labels.q==q_no].set_index('session')['correct'])\n",
    "    lst_valid+=y_test.tolist()\n",
    "    X_test = (X_test-X_train.mean())/X_train.std()\n",
    "    X_train = (X_train-X_train.mean())/X_train.std()\n",
    "    clf = RandomForestClassifier(class_weight='balanced').fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    original_f1score.append(f1_score(y_pred, y_test))\n",
    "    idx = np.argsort(clf.feature_importances_)\n",
    "    features_to_keep[f'{q_no}'] = idx[:len(idx)//2]\n",
    "    X_train_selected = X_train.iloc[:,idx[:len(idx)//2]]\n",
    "    X_test_selected = X_test.iloc[:,idx[:len(idx)//2]]\n",
    "    clf_selected = RandomForestClassifier(class_weight='balanced').fit(X_train_selected, y_train)\n",
    "    y_pred_selected = clf_selected.predict(X_test_selected)\n",
    "    lst_pred+=y_pred.tolist()\n",
    "    lst_pred_selected+=y_pred_selected.tolist()\n",
    "    light_f1score.append(f1_score(y_pred_selected, y_test))\n",
    "    conf_matrix[f'{q_no}'] = confusion_matrix(y_pred, y_test)\n",
    "    conf_matrix_selected[f'{q_no}'] = confusion_matrix(y_pred_selected, y_test)\n",
    "print('Score original: ',f1_score(lst_valid, lst_pred,average='macro'))\n",
    "print('Score light: ',f1_score(lst_valid, lst_pred_selected,average='macro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_light = {}\n",
    "for q_no in range(1,19):\n",
    "    if q_no <= 3:\n",
    "        features = features1\n",
    "    elif q_no <= 13:\n",
    "        features = features2\n",
    "    else:\n",
    "        features = features3\n",
    "    features_light[f'{q_no}'] = features.iloc[:,features_to_keep[f'{q_no}']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_data + 'features_light.pkl', 'wb') as f:\n",
    "    pkl.dump(features_light, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training with Features Light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_data + 'features_light.pkl', 'rb') as f:\n",
    "    features_light = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Score:  0.5850595380500765\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Score:  0.6155132417099873\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Score:  0.6000693893202746\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Score:  0.5991941716019067\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Score:  0.6296733472324534\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Score:  0.6250593899626798\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Score:  0.6231671326279138\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Score:  0.6193990067430697\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Score:  0.617136676536184\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Score:  0.6190384420997331\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Score:  0.617344238021045\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Score:  0.6125125083994297\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Score:  0.6314655504084863\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Score:  0.6276692183694663\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Score:  0.6255329211402998\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Score:  0.6201357639956383\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Score:  0.6145418872144812\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Score:  0.6206151046137819\n"
     ]
    }
   ],
   "source": [
    "lst_valid = []\n",
    "lst_pred = []\n",
    "conf_matrix = {}\n",
    "best_params = {}\n",
    "for q_no in range(1,19):\n",
    "    features = features_light[f'{q_no}']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels.loc[labels.q==q_no].set_index('session')['correct'], test_size=0.2, random_state=42,\n",
    "                                                    stratify=labels.loc[labels.q==q_no].set_index('session')['correct'])\n",
    "    lst_valid+=y_test.tolist()\n",
    "    X_test = (X_test-X_train.mean())/X_train.std()\n",
    "    X_train = (X_train-X_train.mean())/X_train.std()\n",
    "    rf = RandomForestClassifier(class_weight='balanced')\n",
    "    parameters = {'bootstrap': [True, False],\n",
    "                'max_depth': [5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "                'min_samples_leaf': [1, 2, 4],\n",
    "                'min_samples_split': [2, 5, 10],\n",
    "                'n_estimators': [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500]}\n",
    "    rs = BayesSearchCV(rf, parameters, n_iter=10, verbose=1, scoring='f1_macro')\n",
    "    rs.fit(X_train, y_train)\n",
    "    y_pred = rs.predict(X_test)\n",
    "    best_params[f'{q_no}'] = rs.best_params_\n",
    "    lst_pred+=y_pred.tolist()\n",
    "    conf_matrix[f'{q_no}'] = confusion_matrix(y_pred, y_test)\n",
    "    print('Score: ',f1_score(lst_valid, lst_pred,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best_params with pickle\n",
    "with open(path_data + 'best_params.pkl', 'wb') as f:\n",
    "    pkl.dump(best_params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 532  826]\n",
      " [ 752 2603]]\n",
      "[[  11  301]\n",
      " [  89 4312]]\n",
      "[[  33  361]\n",
      " [ 278 4041]]\n",
      "[[ 292  502]\n",
      " [ 659 3260]]\n",
      "[[1058  755]\n",
      " [1071 1829]]\n",
      "[[ 431  718]\n",
      " [ 625 2939]]\n",
      "[[ 563  810]\n",
      " [ 681 2659]]\n",
      "[[ 869 1074]\n",
      " [ 935 1835]]\n",
      "[[ 607  958]\n",
      " [ 636 2512]]\n",
      "[[1105  738]\n",
      " [1226 1644]]\n",
      "[[ 819  937]\n",
      " [ 861 2096]]\n",
      "[[ 282 1088]\n",
      " [ 364 2979]]\n",
      "[[2318  643]\n",
      " [1098  654]]\n",
      "[[ 516  754]\n",
      " [ 862 2581]]\n",
      "[[1154  756]\n",
      " [1292 1511]]\n",
      "[[ 262  647]\n",
      " [ 988 2816]]\n",
      "[[ 441  827]\n",
      " [1030 2415]]\n",
      "[[  26  131]\n",
      " [ 207 4349]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,19):\n",
    "    print(conf_matrix[str(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observation: the light model with xgboost has same f1 score inside the for, but much worse overall (the same metric that they use)\n",
    "# from .65 to .59"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
